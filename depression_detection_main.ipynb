{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOROp-KEb8RN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "OR7doYj-d2ET"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05zwHmDfcEg9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Student Depression Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYk6gPmHnz50",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMWAsC1fysqp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['Profession'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpsBVY2bcGbY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj4wgpMvcH3g",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi5j0RkdcKgJ"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tnv4Uw-cNdU"
      },
      "outputs": [],
      "source": [
        "df_dummies = pd.get_dummies(df)\n",
        "df_dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXU2CSl1cPSm",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(x=df['Depression'])\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvgYCDWPcT-a",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = df.drop(columns=['Depression'])\n",
        "y = df['Depression']\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9zt33g8cXt4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8gduwshctwu"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxIEttdvc_zN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numerical_features = X_resampled.select_dtypes(include=['int64','float64']).columns\n",
        "\n",
        "X_resampled[numerical_features] = scaler.fit_transform(X_resampled[numerical_features])\n",
        "\n",
        "print(X_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYkE0dk8jsWr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "correlation_matrix = X_resampled.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Features')\n",
        "plt.show()\n",
        "\n",
        "sns.pairplot(X_resampled)\n",
        "plt.suptitle('Pairplot of Selected Numerical Features', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for col in X_resampled.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(X_resampled[col], kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for col in X_resampled.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=X_resampled[col])\n",
        "    plt.title(f'Box Plot of {col}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l8UkVySdkAZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwAS-f3Seryy"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "K_96WRJld9Bg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qUwn0R8ew3C",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Nearest Neighbors**"
      ],
      "metadata": {
        "id": "T517FHKWeDSh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNKpCgx6ezHo",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DecisionTree Classifier**"
      ],
      "metadata": {
        "id": "H_Tq4KpLeR2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y07nndae2SW",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomForestClassifier**"
      ],
      "metadata": {
        "id": "-DYIIogjeY4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vst8CsMze5On",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**"
      ],
      "metadata": {
        "id": "4XZFCCmbeefL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlvgCoH7e6_C",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdaBoostClassifier**"
      ],
      "metadata": {
        "id": "A2RSA2CFekSv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqhA7EyUe_Tn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "adaboost = AdaBoostClassifier(n_estimators=50)\n",
        "adaboost.fit(X_train, y_train)\n",
        "y_pred = adaboost.predict(X_test)\n",
        "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLPClassifier**"
      ],
      "metadata": {
        "id": "SkYuHH57espY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc_7h7cbfBw2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred = mlp.predict(X_test)\n",
        "print(\"MLP Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "B_3NQLexe9XT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk29g_yffEDx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train_cnn = np.expand_dims(X_train, axis=-1)\n",
        "X_test_cnn = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "\n",
        "y_train_cnn = to_categorical(y_train, num_classes=2)\n",
        "y_test_cnn = to_categorical(y_test, num_classes=2)\n",
        "\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    Flatten(),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "cnn_model.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test_cnn))\n",
        "\n",
        "\n",
        "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn), axis=1)\n",
        "y_test_cnn_labels = np.argmax(y_test_cnn, axis=1)\n",
        "\n",
        "print(\"CNN Accuracy:\", accuracy_score(y_test_cnn_labels, y_pred_cnn))\n",
        "print(classification_report(y_test_cnn_labels, y_pred_cnn))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SupportVectorMachine**"
      ],
      "metadata": {
        "id": "2lJkrcv5fBKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX0oykmxfILB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "svm_model = SVC(kernel='linear', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fhYoJE0dOoYT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import xgboost as xgb\n",
        "\n",
        "param_grids = {\n",
        "    \"LogisticRegression\": {\n",
        "        \"model\": [LogisticRegression()],\n",
        "        \"model__C\": [0.01, 0.1, 1, 10]\n",
        "    },\n",
        "    \"SVC\": {\n",
        "        \"model\": [SVC()],\n",
        "        \"model__C\": [0.1, 1, 10],\n",
        "        \"model__kernel\": [\"linear\", \"rbf\"]\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        \"model\": [KNeighborsClassifier()],\n",
        "        \"model__n_neighbors\": [3, 5, 7]\n",
        "    },\n",
        "    \"DecisionTree\": {\n",
        "        \"model\": [DecisionTreeClassifier()],\n",
        "        \"model__max_depth\": [3, 5, 10],\n",
        "        \"model__criterion\": [\"gini\", \"entropy\"]\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"model\": [RandomForestClassifier()],\n",
        "        \"model__n_estimators\": [50, 100, 200],\n",
        "        \"model__max_depth\": [None, 10, 20]\n",
        "    },\n",
        "    \"AdaBoost\": {\n",
        "        \"model\": [AdaBoostClassifier()],\n",
        "        \"model__n_estimators\": [50, 100, 200],\n",
        "        \"model__learning_rate\": [0.01, 0.1, 1]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"model\": [xgb.XGBClassifier()],\n",
        "        \"model__n_estimators\": [50, 100, 200],\n",
        "        \"model__learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"model__max_depth\": [3, 5, 10]\n",
        "    },\n",
        "    \"MLPClassifier\": {\n",
        "        \"model\": [MLPClassifier()],\n",
        "        \"model__hidden_layer_sizes\": [(50,), (100,), (50,50)],\n",
        "        \"model__activation\": [\"relu\", \"tanh\"],\n",
        "        \"model__solver\": [\"adam\", \"sgd\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for model_name, param_grid in param_grids.items():\n",
        "    print(f\"Tuning {model_name}...\")\n",
        "    pipeline = Pipeline([(\"model\", param_grid[\"model\"][0])])\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ITmpOF9WS3Ke"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d-Rt0_9HOttL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(hp.Int('units', min_value=32, max_value=128, step=32), activation='relu'))\n",
        "    model.add(Dropout(hp.Float('dropout', 0.1, 0.5, step=0.1)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [0.01, 0.001, 0.0001])),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Keras tuner\n",
        "tuner = kt.Hyperband(build_model, objective='val_accuracy', max_epochs=10, factor=3, directory='my_dir', project_name='depression_detection')\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Hyperparameters for Neural Network: {best_hps.values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XAI-Techniques **"
      ],
      "metadata": {
        "id": "5Tl1xawKfJVJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7k3aPygKlhQp"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j_j6tXINQR1Q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "explainer=shap.LinearExplainer(log_reg,X_train,feature_perturbation='correlation_dependent')\n",
        "shap_values=explainer.shap_values(X_test)\n",
        "shap_df=pd.DataFrame(shap_values,columns=X_test.columns)\n",
        "shap_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y2iBqRk5p8oN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values,X_test,feature_names=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m9bo_YZ3QYmO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "shap.dependence_plot('Financial Stress',shap_values,X_test,feature_names=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lUd2O0F9Qes7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "plt.title('Feature Importance')\n",
        "shap.plots.bar(shap.Explanation(shap_values, data=X_test, feature_names=X_test.columns), max_display=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lightgbm**"
      ],
      "metadata": {
        "id": "rQ1VVCRDfPhR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5bWmq3KKQiby",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "gbm_model = lgb.LGBMClassifier()\n",
        "gbm_model.fit(X_train, y_train)\n",
        "y_pred_gbm = gbm_model.predict(X_test)\n",
        "print(\"GBM Accuracy:\", accuracy_score(y_test, y_pred_gbm))\n",
        "print(classification_report(y_test, y_pred_gbm))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "vKDmpcfJfS_l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JJb5_HEoQ00D",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "X_train_rnn = X_train.values.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_rnn = X_test.values.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "rnn_model = Sequential([\n",
        "    LSTM(units=64, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "rnn_model.fit(X_train_rnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_rnn, y_test))\n",
        "\n",
        "y_pred_rnn = (rnn_model.predict(X_test_rnn) > 0.5).astype(int)\n",
        "print(\"RNN Accuracy:\", accuracy_score(y_test, y_pred_rnn))\n",
        "print(classification_report(y_test, y_pred_rnn))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2d41UtCeSb3x",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM\n",
        "\n",
        "X_train_rnn = X_train.values.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_rnn = X_test.values.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "rnn_model = Sequential([\n",
        "    Bidirectional(LSTM(units=64, activation='relu'), input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "rnn_model.fit(X_train_rnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_rnn, y_test))\n",
        "\n",
        "y_pred_rnn = (rnn_model.predict(X_test_rnn) > 0.5).astype(int)\n",
        "print(\"RNN Accuracy:\", accuracy_score(y_test, y_pred_rnn))\n",
        "print(classification_report(y_test, y_pred_rnn))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_display.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix for Depression Prediction')\n",
        "plt.show()\n",
        "\n",
        "# For more detailed analysis, you can also print the raw numbers\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XAI Techniques - LIME**"
      ],
      "metadata": {
        "id": "QJurkIS7fXYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gKP0-bPZSuoU",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "\n",
        "model=log_reg\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train.values,\n",
        "    feature_names=X_train.columns,\n",
        "    class_names=['No Depression', 'Depression'],\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "\n",
        "instance_idx = 0\n",
        "instance = X_test.iloc[instance_idx]\n",
        "\n",
        "\n",
        "explanation = explainer.explain_instance(\n",
        "    data_row=instance.values,\n",
        "    predict_fn=model.predict_proba,\n",
        "    num_features=10\n",
        ")\n",
        "\n",
        "\n",
        "explanation.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EL6LILtFS6Hp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "print(pd.__version__)\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Counterfactual Explanations**"
      ],
      "metadata": {
        "id": "uoI6asTAfvIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dic4vBzWS-BG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install dice-ml -q\n",
        "import dice_ml\n",
        "from dice_ml import Dice\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "continuous_feature_names = [\n",
        "    'Age', 'Year of study', 'CGPA', 'Financial Stress', 'Living expenses',\n",
        "    'Academic performance', 'Social support', 'Sleep quality', 'Health issues',\n",
        "    'Extra-curricular activities'\n",
        "]\n",
        "continuous_features_present = list(set(continuous_feature_names) & set(X_resampled.columns))\n",
        "\n",
        "\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "df_resampled['Depression'] = y_resampled\n",
        "\n",
        "d = dice_ml.Data(dataframe=df_resampled,\n",
        "                 continuous_features=continuous_features_present,\n",
        "                 outcome_name='Depression')\n",
        "\n",
        "m = dice_ml.Model(model=log_reg, backend='sklearn')\n",
        "\n",
        "\n",
        "exp = Dice(d, m, method=\"random\")\n",
        "\n",
        "\n",
        "query_instance_index = 0\n",
        "query_instance = X_resampled.iloc[[query_instance_index]].drop(columns=['Depression'], errors='ignore')\n",
        "\n",
        "e = exp.generate_counterfactuals(query_instance,\n",
        "                              total_CFs=5,\n",
        "                              desired_class=\"opposite\")\n",
        "\n",
        "cf_df = e.cf_examples_list[0].final_cfs_df\n",
        "\n",
        "\n",
        "all_features = X.columns\n",
        "dummy_array = np.zeros((len(cf_df), len(all_features)))\n",
        "\n",
        "\n",
        "for feature in cf_df.columns:\n",
        "    if feature in all_features:\n",
        "        col_idx = list(all_features).index(feature)\n",
        "        dummy_array[:, col_idx] = cf_df[feature]\n",
        "\n",
        "dummy_array = scaler.inverse_transform(dummy_array)\n",
        "\n",
        "cf_df_original = pd.DataFrame(dummy_array, columns=all_features)\n",
        "\n",
        "\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    if col in label_encoders:\n",
        "\n",
        "        cf_df_original[col] = label_encoders[col].inverse_transform(\n",
        "            cf_df_original[col].round().astype(int)\n",
        "        )\n",
        "\n",
        "original_instance = query_instance.copy()\n",
        "dummy_original = np.zeros((1, len(all_features)))\n",
        "for i, feature in enumerate(all_features):\n",
        "    if feature in original_instance.columns:\n",
        "        dummy_original[0, i] = original_instance[feature].values[0]\n",
        "dummy_original = scaler.inverse_transform(dummy_original)\n",
        "original_instance_original = pd.DataFrame(dummy_original, columns=all_features)\n",
        "\n",
        "\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    if col in label_encoders:\n",
        "        original_instance_original[col] = label_encoders[col].inverse_transform(\n",
        "            original_instance_original[col].round().astype(int)\n",
        "        )\n",
        "\n",
        "changed_features_list = []\n",
        "for i in range(len(cf_df_original)):\n",
        "    changed_features = []\n",
        "    for col in cf_df_original.columns:\n",
        "        original_val = original_instance_original[col].values[0]\n",
        "        cf_val = cf_df_original.iloc[i][col]\n",
        "\n",
        "\n",
        "        if col in continuous_features_present:\n",
        "            if not np.isclose(original_val, cf_val, rtol=0.05):\n",
        "                changed_features.append(col)\n",
        "\n",
        "        else:\n",
        "            if original_val != cf_val:\n",
        "                changed_features.append(col)\n",
        "    changed_features_list.append(changed_features)\n",
        "\n",
        "\n",
        "print(\"=== Complete Analysis ===\")\n",
        "print(f\"{'':<4}{'Age':<6}{'CGPA':<6}{'Study Satisfaction':<20}{'Sleep Duration':<15}\")\n",
        "for i, row in original_instance_original.iterrows():\n",
        "    print(f\"{i:<4}{row['Age']:<6.1f}{row['CGPA']:<6.1f}{row['Study Satisfaction']:<20}{row['Sleep Duration']:<15.1f}\")\n",
        "\n",
        "\n",
        "feature_direction = {\n",
        "    'CGPA': 'increase',\n",
        "    'Sleep quality': 'increase',\n",
        "    'Financial Stress': 'decrease',\n",
        "    'Living expenses': 'decrease',\n",
        "    'Social support': 'increase',\n",
        "    'Academic performance': 'increase',\n",
        "    'Health issues': 'decrease',\n",
        "    'Extra-curricular activities': 'increase',\n",
        "    'Age': 'neutral',\n",
        "    'Year of study': 'neutral',\n",
        "    'Course': 'neutral',\n",
        "    'Gender': 'neutral',\n",
        "    'City': 'neutral',\n",
        "    'Academic Pressure': 'decrease',\n",
        "}\n",
        "\n",
        "print(\"\\n=== Clear Recommendations ===\")\n",
        "\n",
        "for i, cf_row in cf_df_original.iterrows():\n",
        "    changed_features = []\n",
        "    for col in cf_df_original.columns:\n",
        "        original_val = original_instance_original[col].values[0]\n",
        "        cf_val = cf_row[col]\n",
        "\n",
        "\n",
        "        is_changed = False\n",
        "        if col in continuous_features_present:\n",
        "            is_changed = not np.isclose(original_val, cf_val, rtol=0.05)\n",
        "        else:\n",
        "            is_changed = original_val != cf_val\n",
        "\n",
        "        if not is_changed:\n",
        "            continue\n",
        "\n",
        "        direction = feature_direction.get(col, 'neutral')\n",
        "        if direction == 'increase' and cf_val <= original_val:\n",
        "            continue\n",
        "        if direction == 'decrease' and cf_val >= original_val:\n",
        "            continue\n",
        "\n",
        "        changed_features.append((col, original_val, cf_val))\n",
        "\n",
        "    if len(changed_features) > 0:\n",
        "        print(f\"\\nScenario {i+1}:\")\n",
        "        for feature, original_val, cf_val in changed_features:\n",
        "\n",
        "            if feature == 'CGPA':\n",
        "                recommendation = f\"  • Improve academic performance: Aim for a CGPA of around {cf_val:.2f} (currently {original_val:.2f}). Seek tutoring, study groups, or time management strategies.\"\n",
        "            elif feature == 'Sleep quality':\n",
        "                recommendation = f\"  • Prioritize better sleep: Aim for a sleep quality of {cf_val:.1f} (currently {original_val:.1f}). Establish a bedtime routine or consult a sleep specialist if needed.\"\n",
        "            elif feature == 'Financial Stress':\n",
        "                recommendation = f\"  • Reduce financial stress: Try bringing stress levels down to {cf_val:.1f} (currently {original_val:.1f}). Look into financial aid, budgeting tools, or part-time jobs.\"\n",
        "            elif feature == 'Living expenses':\n",
        "                recommendation = f\"  • Lower your living expenses: Consider reducing costs to around {cf_val:.1f} (currently {original_val:.1f}) by exploring affordable housing or shared accommodations.\"\n",
        "            elif feature == 'Social support':\n",
        "                recommendation = f\"  • Strengthen your social support: Improve social interactions to a level of {cf_val:.1f} (currently {original_val:.1f}). Join groups, stay connected with friends/family.\"\n",
        "            elif feature == 'Academic performance':\n",
        "                recommendation = f\"  • Boost academic performance: Aim for {cf_val:.1f} (currently {original_val:.1f}). Use goal-setting, time blocking, and feedback sessions to help.\"\n",
        "            elif feature == 'Health issues':\n",
        "                recommendation = f\"  • Address health concerns: Reduce health-related issues to {cf_val:.1f} (currently {original_val:.1f}). Consult health professionals and prioritize self-care.\"\n",
        "            elif feature == 'Extra-curricular activities':\n",
        "                recommendation = f\"  • Get involved: Increase participation in extracurricular activities to {cf_val:.1f} (currently {original_val:.1f}) for balance and personal growth.\"\n",
        "            elif feature == 'Academic Pressure':\n",
        "                recommendation = f\"  • Manage academic pressure: Consider lowering academic pressure to {cf_val:.1f} (currently {original_val:.1f}). Use stress-reduction techniques and manage expectations.\"\n",
        "            elif feature == 'Year of study':\n",
        "                recommendation = f\"  • Year-specific support: You may benefit from resources tailored to Year {int(cf_val)} (currently Year {int(original_val)}).\"\n",
        "            elif feature == 'Age':\n",
        "                recommendation = f\"  • Age-related context: At {cf_val:.0f} years (currently {original_val:.0f}), consider age-appropriate wellness and mental health resources.\"\n",
        "            elif feature == 'Course':\n",
        "                recommendation = f\"  • Reconsider your course: Explore if the course change from '{original_val}' to '{cf_val}' aligns more with your interests and well-being.\"\n",
        "            elif feature == 'Gender':\n",
        "                recommendation = f\"  • Gender-specific well-being: If gender has changed from '{original_val}' to '{cf_val}', consider tailored support groups or safe spaces.\"\n",
        "            elif feature == 'City':\n",
        "                recommendation = f\"  • Relocation consideration: A change in city from '{original_val}' to '{cf_val}' might reflect environmental or lifestyle influences on well-being.\"\n",
        "            else:\n",
        "                recommendation = f\"  • Adjust {feature}: Consider changing '{feature}' from '{original_val}' to '{cf_val}'.\"\n",
        "\n",
        "            print(recommendation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Curve**"
      ],
      "metadata": {
        "id": "l6SCF9Gnf2aa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ezJymBRIS_3v",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': log_reg,\n",
        "    'KNN': knn,\n",
        "    'Decision Tree': dt,\n",
        "    'Random Forest': rf,\n",
        "    'XGBoost': xgb_model,\n",
        "    'AdaBoost': adaboost,\n",
        "    'MLP': mlp,\n",
        "    'CNN': cnn_model,\n",
        "    'SVM': svm_model\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    if model_name == 'CNN':\n",
        "        y_pred_prob = model.predict(X_test_cnn)[:, 1]  # Assuming binary classification\n",
        "    else:\n",
        "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PG4Ds4S_SlSd"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers -q\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Load your CSV\n",
        "\n",
        "df = pd.read_csv(\"Student Depression Dataset.csv\")\n",
        "\n",
        "# Reduce the sample size to 100\n",
        "\n",
        "df = df.sample(n=100, random_state=42)  # Take a random sample of 100 rows\n",
        "\n",
        "# Transform each row into a sentence\n",
        "\n",
        "def row_to_sentence(row):\n",
        "\n",
        "    return (\n",
        "\n",
        "        f\"A {int(row['Age'])}-year-old {row['Gender']} from {row['City']}, studying {row['Degree']}, \"\n",
        "\n",
        "        f\"experiences academic pressure of level {row['Academic Pressure']} and work pressure of level {row['Work Pressure']}. \"\n",
        "\n",
        "        f\"They have a CGPA of {row['CGPA']}, study satisfaction level {row['Study Satisfaction']}, and job satisfaction level {row['Job Satisfaction']}. \"\n",
        "\n",
        "        f\"They sleep {row['Sleep Duration']}, follow a {row['Dietary Habits']} diet, and spend {row['Work/Study Hours']} hours per day on work or study. \"\n",
        "\n",
        "        f\"Suicidal thoughts: {row['Have you ever had suicidal thoughts ?']}, Financial stress level: {row['Financial Stress']}, \"\n",
        "\n",
        "        f\"Family history of mental illness: {row['Family History of Mental Illness']}. Depression label: {row['Depression']}.\"\n",
        "\n",
        "    )\n",
        "\n",
        "df['text'] = df.apply(row_to_sentence, axis=1)\n",
        "\n",
        "# Create Hugging Face Dataset\n",
        "\n",
        "dataset = Dataset.from_pandas(df[['text', 'Depression']])\n",
        "\n",
        "# Load tokenizer and model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Preprocessing function for tokenization\n",
        "\n",
        "def preprocess_function(examples):\n",
        "\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
        "\n",
        "# Apply preprocessing\n",
        "\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Rename 'Depression' column to 'labels'\n",
        "\n",
        "dataset = dataset.rename_column('Depression', 'labels')\n",
        "\n",
        "# Set format to 'torch'\n",
        "\n",
        "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Split dataset into train and test\n",
        "\n",
        "# Use 'seed' instead of 'random_state' for Hugging Face Datasets\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Define compute_metrics function for evaluation\n",
        "\n",
        "def compute_metrics(pred):\n",
        "\n",
        "    labels = pred.label_ids\n",
        "\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    probs = pred.predictions[:, 1]  # Probabilities for class 1 (Depression)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    prec = precision_score(labels, preds)\n",
        "\n",
        "    rec = recall_score(labels, preds)\n",
        "\n",
        "    f1 = f1_score(labels, preds)\n",
        "\n",
        "    auc = roc_auc_score(labels, probs)\n",
        "\n",
        "    return {\n",
        "\n",
        "        'accuracy': acc,\n",
        "\n",
        "        'precision': prec,\n",
        "\n",
        "        'recall': rec,\n",
        "\n",
        "        'f1': f1,\n",
        "\n",
        "        'auc': auc\n",
        "\n",
        "    }\n",
        "\n",
        "# Training arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "\n",
        "    output_dir=\"./bert_results\",\n",
        "\n",
        "    per_device_train_batch_size=8,\n",
        "\n",
        "    num_train_epochs=3,\n",
        "\n",
        "    logging_dir=\"./logs\",\n",
        "\n",
        "    save_strategy=\"no\",\n",
        "\n",
        "    load_best_model_at_end=True,  # Load the best model based on evaluation metric\n",
        "\n",
        "    metric_for_best_model=\"f1\"    # Use F1-score as the metric for selecting the best model\n",
        "\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "\n",
        "    model=model,\n",
        "\n",
        "    args=training_args,\n",
        "\n",
        "    train_dataset=dataset['train'],\n",
        "\n",
        "    eval_dataset=dataset['test'],\n",
        "\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "\n",
        "for metric, value in eval_results.items():\n",
        "\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frM2EI6USuQT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}